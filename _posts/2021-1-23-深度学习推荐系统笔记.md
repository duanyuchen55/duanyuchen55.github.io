---
title: 深度学习推荐系统笔记
tags: 
 - DL
 - RS
mathjax: true
mathjax_autoNumber: true
comment: true
key: 深度学习推荐系统笔记
---
[toc]

## 3.7 FM与深度学习模型的结合

### 3.7.1 FNN——用FM的隐向量完成Embedding层初始化

​		神经网络的参数初始化通常采用不包含任何先验信息的随机初始化，而Embedding层的输入极端稀疏化，导致Embedding层收敛缓慢，且Embedding层参数量占绝大部分，进而导致模型收敛受限于Embedding层。

​		FNN模型解决上述问题的思路：使用FM模型训练好的各特征隐向量初始化Embedding层的参数（引入先验信息）**书p79：图3-8及下面第一段话**

​		FNN模型也为Embedding预训练提供了借鉴思路。

​		

### 3.7.2 DeepFM——用FM代替Wide部分

​		FNN把FM的训练结果作为初始化权重，并未对神经网络的结构进行更改。

​		DeepFM对Wide&Deep的改进在于：用FM替换了Wide部分，加强了浅层网络部分特征组合的能力。**书p80：图3-9及下面第一段话**

​		针对Wide&Deep的改进动机，DeepFM和Deep&Cross完全一样，只不过进行特征组合的方法不一样，前者使用FM，后者使用多层Cross网络。



### 3.7.3 NFM——FM的神经网络化尝试

​		在数学形式上，NFM模型的主要思路是用一个表达能力更强的函数代替FM中的二阶隐向量内积的部分
$$
\hat{y}_{FM}(x) = w_0+\sum_{i=1}^N{w_ix_i}+\sum_{i=1}^N\sum_{j=i+1}^N{v_i^tv_j\cdot x_ix_j}
$$

$$
\hat{y}_{NFM}(x)=w_0+\sum_{i=1}^{N}w_ix_i+f(x)
$$


​		$f(x)$的构造工作可以交由某个深度学习网络来完成，并且通过BP来学习。

​		NFM的这个神经网络架构特点：在Embedding层和多层神经网络之间加入特征交叉池化层。

​		若把NFM的一阶部分看作一个线性模型，则NFM架构也可以视为Wide&Deep模型的进化。NFM模型对Wide&Deep模型的Deep部分加入了特征交叉池化层，加强了特征交叉。



### 3.7.4 基于FM的深度学习模型的优点和局限性

FNN、DeepFM、NFM都是在经典的多层神经网络的基础上加入有针对性的特征交叉操作，使模型具有更强的非线性表达能力。

特征工程的思路已经穷尽了可能的尝试，提升空间很小。



## 3.8 注意力机制在推荐模型中的应用

### 3.8.1 AFM——引入注意力机制的FM



### 3.8.2 DIN——引入注意力机制的深度学习网络

### 3.8.3 注意力机制对推荐系统的启发

## 3.9 DIEN——序列模型与推荐系统的结合